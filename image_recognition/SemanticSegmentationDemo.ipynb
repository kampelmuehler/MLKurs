{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnfiMw3OIRbR1jHPUJNad1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kampelmuehler/MLKurs/blob/main/image_recognition/SemanticSegmentationDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XwbGN2aQNZ3R",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Setup\n",
        "import torch\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import urllib\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "weights = models.segmentation.DeepLabV3_ResNet101_Weights.DEFAULT\n",
        "transform = models.segmentation.DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1.transforms()\n",
        "model = models.segmentation.deeplabv3_resnet101(weights=weights)\n",
        "model.eval()\n",
        "labels = ast.literal_eval(urllib.request.urlopen(\"https://raw.githubusercontent.com/kampelmuehler/MLKurs/main/image_recognition/VOC_classes.txt\").read().decode('utf-8'))\n",
        "\n",
        "\n",
        "def read_image(url):\n",
        "  req = urllib.request.Request(\n",
        "    url, \n",
        "    data=None, \n",
        "    headers={\n",
        "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'\n",
        "    }\n",
        "  )\n",
        "  img = Image.open(urllib.request.urlopen(req)).convert(\"RGB\")\n",
        "  thumbnail = img.copy()\n",
        "  thumbnail.thumbnail((400, 400), Image.ANTIALIAS)\n",
        "  display(thumbnail)\n",
        "  return transform(img).unsqueeze(0), img, thumbnail.size\n",
        "\n",
        "palette = torch.tensor([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\n",
        "colors = torch.as_tensor([i for i in range(21)])[:, None] * palette\n",
        "colors = (colors % 255).numpy().astype(\"uint8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COCO VOC Subset Semantische Segmentierung\n",
        "\n",
        "Hier könnt ihr ein auf MobileNetv3 basierendes DeepLabV3 Modell, welches auf einem COCO subset mit VOC labels trainiert ist, ausprobieren. Einfach eine url zu einem Bild einfügen.\n",
        "\n",
        "Die Klassen finden sie in der Variable `labels`."
      ],
      "metadata": {
        "id": "2JvsKQMjOBmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"\"\n",
        "img_tensor, img, thumbnail_size = read_image(url)\n",
        "result = model(img_tensor)['out'][0].argmax(0)\n",
        "\n",
        "result_array = result.byte().cpu().numpy()\n",
        "output = \"Gefundene Klassen: \"\n",
        "for c in np.unique(result_array):\n",
        "  output += f\"{labels[c]}, \"\n",
        "print(output[:-2])\n",
        "result_img = Image.fromarray(result_array).resize(thumbnail_size)\n",
        "result_img.putpalette(colors)\n",
        "result_img = result_img.convert(\"RGBA\")\n",
        "img = img.resize(thumbnail_size).convert(\"RGBA\")\n",
        "display(Image.blend(img, result_img, 0.7))"
      ],
      "metadata": {
        "id": "g-uMGrYQN-1C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}