{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kampelmuehler/MLKurs/blob/main/LinearRegressionAufgaben.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP_rmMTRuZqx"
      },
      "source": [
        "# Linear Regression: Gradient Descent Lösung\n",
        "\n",
        "Linear Regression Probleme lassen sich zum einen mit numerischer Optimierung über Gradient Descent lösen.\n",
        "\n",
        "$\\hat{y} = kx + d$ entspricht $\\hat{Y} = WX + b$\n",
        "\n",
        "Die Kostenfunktion und dazugehörigen Ableitungen der einzelnen Parameter sind gegeben durch:\n",
        "\n",
        "$$ J = \\frac{1}{m} \\sum_{i=1}^m  (y_i - \\hat{y_i})^2$$\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial W} = -\\frac{2}{m} \\sum_{i=1}^m x_i (y_i - \\hat{y_i})$$\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial b} = -\\frac{2}{m} \\sum_{i=1}^m (y_i - \\hat{y_i})$$\n",
        "\n",
        "Mittels Gradient Descent lassen sich die Parameter wie folgt aktualisieren:\n",
        "\n",
        "$$ W_t = W_{t-1} - \\lambda\\frac{\\partial J}{\\partial W} $$\n",
        "\n",
        "$$ b_t = b_{t-1} - \\lambda\\frac{\\partial J}{\\partial b} $$\n",
        "\n",
        "Implementieren Sie die Funktionen `predict` und `update_weights` der Klasse `LinearRegression`.\n",
        "\n",
        "Berechnen sie den $MAE=\\frac{1}{m} \\sum_{i=1}^m|y_i^{test} - \\hat{y}_i^{test}|$ am Test Set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j67ODy8mSj6O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class LinearRegression():\t\n",
        "\tdef __init__(self, learning_rate, iterations):\t\t\n",
        "\t\tself.learning_rate = learning_rate\n",
        "\t\tself.iterations = iterations\n",
        "\t\t\n",
        "\t# Trainingsfunktion\n",
        "\tdef fit(self, X, Y):\n",
        "\t\t# Initialisierung\n",
        "\t\tself.W = 0\n",
        "\t\tself.b = 0\n",
        "\t\tself.X = X[:, 0]\n",
        "\t\tself.Y = Y\n",
        "\t\t\n",
        "\t\t# Lernen mit Gradient Descent\n",
        "\t\tfor i in range(self.iterations):\t\n",
        "\t\t\tself.update_weights()\n",
        "\t\t\t\n",
        "\t\treturn self\n",
        "\n",
        "\t# Einzelner Gradient Descent Schritt\n",
        "\tdef update_weights(self):\n",
        "\t\traise NotImplementedError\n",
        "\n",
        "\t# Y = wX + b\n",
        "\tdef predict(self, X):\n",
        "\t\traise NotImplementedError\n",
        "\n",
        "\n",
        "def main() :\n",
        "\t# Daten laden\n",
        "\timport pandas as pd\n",
        "\tdf = pd.read_csv(\"https://raw.githubusercontent.com/mohit-baliyan/references/master/salary_data.csv\")\n",
        "\tX = df.iloc[:,:-1].values  # Vorerfahrung in Jahren (m, 1)\n",
        "\tY = df.iloc[:,1].values  # Gehalt (m, 1)\n",
        "\n",
        "\t# Daten in Trainings- und Testdaten splitten - 80/20\n",
        "\tids = np.arange(X.shape[0])\n",
        "\tnp.random.shuffle(ids)\n",
        "\tnp.random.seed(0)\n",
        "\tsplit = int(X.shape[0] * 0.8)\n",
        "\ttrain_ids = ids[:split]\n",
        "\ttest_ids = ids[split:]\n",
        "\tX_train = X[train_ids]\n",
        "\tY_train = Y[train_ids]\n",
        "\tX_test = X[test_ids]\n",
        "\tY_test = Y[test_ids]\n",
        "\t\n",
        "\t# Model trainieren\n",
        "\tmodel = LinearRegression(iterations = 1000, learning_rate = 0.01)\n",
        "\tmodel.fit(X_train, Y_train)\n",
        "\t\n",
        "\t# Überprüfen am Test split\n",
        "\tY_test_pred = model.predict(X_test)\n",
        "\tmae = None\n",
        "\tprint(f\"W_pred={model.W:.02f}\")\n",
        "\tprint(f\"b_pred={model.b:.02f}\")\n",
        "\tprint(f\"MAE={mae}\")\n",
        "\t\n",
        "\t# Visualisierung am Test Set\n",
        "\tplt.figure()\n",
        "\tplt.scatter(X_test, Y_test, color='blue')\n",
        "\tplt.plot(X_test, Y_test_pred, color='orange')\n",
        "\tplt.title('Gehalt vs Berufserfahrung')\n",
        "\tplt.xlabel('Berufserfahrung in Jahren')\n",
        "\tplt.ylabel('Gehalt')\n",
        "\tplt.show()\n",
        "\t\n",
        "if __name__ == \"__main__\" :\n",
        "\tmain()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF6s6EsLYQlS"
      },
      "source": [
        "# Linear Regression: Analytische Lösung\n",
        "\n",
        "Für Linear Regression Probleme gibt es eine analytische Lösung der Form\n",
        "\n",
        "$$\\Theta =  \\begin{bmatrix} W \\\\ b \\end{bmatrix}=(X^TX)^{-1}X^TY$$\n",
        "\n",
        "wobei X die unabhängigen Variablen darstellt und Y die abhängigen Variablen.\n",
        "\n",
        "Erweitern Sie die Klasse `LinearRegression` um eine Funktion `solve(X, Y)` welche die analytische Lösung für W und b berechnet.\n",
        "\n",
        "Hinweis: `np.inv()`, `np.hstack()`, `np.ones()`, $X^T$ = `X.T`\n",
        "\n",
        "# Linear Regression: Scikit-learn Lösung\n",
        "\n",
        "Erweitern Sie die Klasse `LinearRegression` um eine Funktion `solve_sklearn(X, Y)` welche die Lösung für W und b mittels `sklearn` findet.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
        "\n",
        "Hinweis: intercept entspricht b\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Vergleichen Sie die Parameter und MAEs der 3 verschiedenen Lösungen.\n",
        "\n",
        "Welche Methode verwendet `sklearn`?\n",
        "\n",
        "Welche Methode erreicht denn geringsten Fehler?\n",
        "\n",
        "Bonus: Berechnen Sie mittels `r2_score` aus `sklearn` die $R^2$ Metrik für die unterschiedlichen Lösungen. Was sagt diese aus?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}